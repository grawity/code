#!/usr/bin/env python3
import json
from nullroute.core import Core
from nullroute.misc import set_file_attr, set_file_attrs
from nullroute.api.pixiv import PixivClient, PixivApiClient
from nullroute.scrape import Scraper
import os
import re
import sys

def is_nonempty(file):
    if os.path.exists(file):
        if os.stat(file).st_size > 0:
            return True
    return False

class PixivGrabber():
    basename_re = re.compile(r"(?P<id>\d+)_p(?P<page>\d+)")
    member_re = re.compile(r"https?://www\.pixiv\.net/member(?:_illust)?\.php\?id=(?P<id>\d+)")
    member_re2 = re.compile(r"https?://www\.pixiv\.net/(?:en/)?users/(?P<id>\d+)")
    illust_re = re.compile(r"https?://www\.pixiv\.net/member_illust\.php\?mode=(?P<mode>manga|medium|big)&illust_id=(?P<id>\d+)")
    illust_re2 = re.compile(r"https?://www\.pixiv\.net/member_illust\.php\?illust_id=(?P<id>\d+)&mode=(?P<mode>manga|medium|big)")
    illust_re3 = re.compile(r"https?://www\.pixiv\.net/(?:en/)?artworks/(?P<id>\d+)")
    bigpage_re = re.compile(r"https?://www\.pixiv\.net/member_illust\.php\?mode=(?P<mode>manga_big)&illust_id=(?P<id>\d+)&page=(?P<page>\d+)")
    pximg_re = re.compile(r"https?://[0-9a-z-]+\.pximg\.net/img.*/(?P<id>\d+)_p(?P<page>\d+)\.\w+")
    fanbox_post_re = re.compile(r"https://www.pixiv.net/fanbox/creator/\d+/post/(?P<id>\d+)")
    fanbox_img_re = re.compile(r"https://fanbox.pixiv.net/images/post/(?P<id>\d+)/(?P<img>[^.?#]+)")

    def __init__(self):
        self.pixiv = PixivClient()
        self.api = PixivApiClient()
        self.api._authenticate()
        self.web = None
        self.s = Scraper()
        self.s.ua = self.api.ua
        self.write_log = True

    def init_web_client(self):
        if not self.web:
            from nullroute.api.pixiv_web import PixivWebClient
            self.web = PixivWebClient()
            self.web._authenticate()
            self.s.ua = self.web.ua

    def save_file(self, url, name=None, attrs=None):
        if not name:
            name = os.path.basename(url)
        if is_nonempty(name):
            Core.debug("file %r already exists, skipping" % name)
            return
        Core.debug("saving %s to %r" % (url, name))
        referer = url
        if attrs:
            referer = attrs.get("xdg.referrer.url", url)
        name = self.s.save_file(url, name,
                                referer=referer,
                                progress=True)
        if attrs:
            set_file_attrs(name, attrs)

    def _append_to_log(self, work):
        with open("pixiv%s.txt" % work.user.id, "a") as log:
            log.write("-- %s --\n" % work.id)
            log.write("Title: ｢%s｣\n" % work.title)
            log.write("Origin: <%s>\n" % self.pixiv.fmt_illust_url(work.id))
            log.write("\n")
            if work.caption:
                log.write("%s\n" % work.caption.replace("\r\n", "\n"))
                log.write("\n")

    def _save_work(self, work, only_pages=None):
        if (work.is_manga or work.type == "ugoira") and not work.metadata:
            Core.info("- refreshing metadata for work %s" % work.id)
            work = self.api.get_illust_info(work.id)

        attrs = {
            "dublincore.title": work.title,
            "dublincore.creator": "%s_pixiv%s" % (work.user.name, work.user.id),
            "xdg.referrer.url": self.pixiv.fmt_illust_url(work.id),
        }

        if work.type == "ugoira":
            delays = [frame.delay_msec for frame in work.metadata.frames]
            n_delays = len({*delays})
            if n_delays > 1:
                with open("%s_delays.json" % work.id, "w") as fh:
                    fh.write(json.dumps(delays))
            for size, url in work.metadata.zip_urls.items():
                assert(size.startswith("ugoira"))
                assert(url.endswith(".zip"))
                if n_delays == 1:
                    zip_file = "%s_%s@%s.zip" % (work.id, size, delays[0])
                else:
                    zip_file = "%s_%s.zip" % (work.id, size)
                Core.info("- saving %r" % zip_file)
                self.save_file(url, zip_file, attrs=attrs)
        elif work.is_manga:
            Core.debug("- page whitelist %r" % only_pages)
            for j, page in enumerate(work.metadata.pages):
                # only_pages is 0-indexed, as are pages themselves,
                # but UI will show 1-indexed numbers
                if only_pages and j not in only_pages:
                    Core.debug("- skipping page %s, not in whitelist" % (j+1))
                    continue
                Core.info("- saving %r (page %s of %s)",
                          os.path.basename(page.image_urls["large"]),
                          j+1, work.page_count)
                self.save_file(page.image_urls["large"], attrs=attrs)
        else:
            self.save_file(work.image_urls["large"], attrs=attrs)

        if self.write_log:
            self._append_to_log(work)

    def save_one_work(self, illust_id, **kwargs):
        work = self.api.get_illust_info(illust_id)
        Core.info("downloading work: %s ｢%s｣" % (work.id, work.title))
        self._save_work(work, **kwargs)

    def save_all_member_works(self, member_id, start_page=1):
        Core.info("getting works of user %s" % member_id)
        while start_page:
            works_r = self.api.get_member_works(member_id, page=start_page)
            Core.info("got page %d/%d (%d works out of %d)" % (
                        works_r.pagination.current,
                        works_r.pagination.pages,
                        works_r.count,
                        works_r.pagination.total,
                      ))
            for i, work in enumerate(works_r.response):
                i_offset = (works_r.pagination.current - 1) * works_r.pagination.per_page
                i_global = (i + 1) + i_offset
                Core.info("downloading work %s of %s: %s ｢%s｣" % (
                            i_global,
                            works_r.pagination.total,
                            work.id,
                            work.title,
                          ))
                self._save_work(work)
            start_page = works_r.pagination.next

    def save_fanbox_post(self, post_id, only_img_ids=None):
        self.init_web_client()
        post = self.web.get_fanbox_post(post_id)
        Core.info("downloading fanbox post: %s ｢%s｣" % (post["id"], post["title"]))
        prefix = self.pixiv.fmt_member_tag(post["user"]["userId"],
                                           post["user"]["name"])
        attrs = {
            "dublincore.title": post["title"],
            "dublincore.creator": prefix,
            "xdg.referrer.url": "https://www.pixiv.net/fanbox/creator/%s/post/%s" \
                                 % (post["user"]["userId"], post["id"]),
        }
        try:
            images = post["body"]["images"]
        except KeyError:
            try:
                images = [post["body"]["imageMap"][b["imageId"]]
                          for b in post["body"]["blocks"]
                          if b["type"] == "image"]
            except KeyError:
                import pprint
                pprint.pprint(post)
                raise
        for i, img in enumerate(images):
            if only_img_ids and img["id"] not in only_img_ids:
                Core.debug("- image %r not in wanted %r", img, only_img_ids)
                continue
            url = img["originalUrl"]
            filename = "%s fanbox%s_p%s %s" % (prefix, post["id"], i,
                                               os.path.basename(url))
            Core.info("- saving %r (image %s of %s)",
                      filename, i+1, len(images))
            self.save_file(url, filename, attrs)

c = PixivGrabber()
c.write_log = False

args = sys.argv[1:]
if not args:
    Core.die("no URLs specified")

for arg in args:
    if arg == "--log":
        c.write_log = True
        continue

    m = c.bigpage_re.match(arg) \
        or c.pximg_re.match(arg) \
        or c.basename_re.match(arg)
    if m:
        illust_id = int(m.group("id"))
        page_no = int(m.group("page"))
        c.save_one_work(illust_id, only_pages=[page_no])
        continue

    m = c.illust_re.match(arg) or c.illust_re2.match(arg)
    if m:
        mode = m.group("mode")
        if mode not in {"medium", "manga"}:
            Core.err("BUG: unrecognized mode %r in URL %r" % (mode, arg))
        illust_id = int(m.group("id"))
        c.save_one_work(illust_id)
        continue

    m = c.illust_re3.match(arg)
    if m:
        illust_id = int(m.group("id"))
        c.save_one_work(illust_id)
        continue

    m = c.member_re.match(arg) or c.member_re2.match(arg)
    if m:
        member_id = int(m.group("id"))
        c.save_all_member_works(member_id)
        continue

    m = c.fanbox_post_re.match(arg)
    if m:
        post_id = int(m.group("id"))
        c.save_fanbox_post(post_id)
        continue

    m = c.fanbox_img_re.match(arg)
    if m:
        post_id = int(m.group("id"))
        img_id = m.group("img")
        c.save_fanbox_post(post_id, {img_id})
        continue

    try:
        illust_id = int(arg)
    except ValueError:
        Core.err("unrecognized argument %r" % arg)
    else:
        c.save_one_work(illust_id)
