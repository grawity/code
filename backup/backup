#!/usr/bin/env bash

. lib.bash || exit

progname_prefix=0

# configuration

local_config_file=$path_config/backup.conf.sh

annexes=(~/Attic/{Annex,Software,Videos,Anime})
hosts=()
push_volume=

borg_args=(
	--progress
	--one-file-system
	--exclude-caches
	--exclude-if-present=".nobackup"
	--keep-exclude-tags
)

borg_keep=(
	--keep-daily 7
	--keep-weekly 8
	--keep-monthly 24
)

if [[ -f $local_config_file ]]; then
	. "$local_config_file" || die "failed to load configuration from '$local_config_file'"
else
	warn "config file '$local_config_file' missing"
fi

declare -r annexes
declare -r hosts
declare -r push_volume

# misc

bvol=${push_volume:-/mnt/backup}
conf=${path_sync_config:-$path_config/synced}

debug "config dir: '$conf'"

lock_path=
lock_fd=
failed_jobs=()

take_lock() {
	local job=$1

	lock_path=$path_runtime/backup-$1.lock
	exec {lock_fd}<>$lock_path
	flock -x -n $lock_fd || {
		if read ldate < "$lock_path" || true; then
			lmsg="started on $(date -d "$ldate" +"%F %T")"
		else
			lmsg="status unknown"
		fi
		die "job $job is already running ($lmsg)"
	}
	echo "$(date -Isecond) $*" >&$lock_fd
}

drop_lock() {
	exec {lock_fd}<&-
	rm -f "$lock_path"
}

is_older_than() {
	local path=$1 seconds=$2
	local a=$(date +%s)
	local b=$(stat -c %Y "$path" 2>/dev/null || echo 0)
	(( a - b > seconds ))
}

check_stamp() {
	local name=$1 days=$2 hours=$3
	local stamp_path=$path_cache/backup/$name.stamp
	is_older "$stamp_path" $(( days*86400 + hours*3600 ))
}

update_stamp() {
	local name=$1
	local stamp_path=$path_cache/backup/$name.stamp
	install -Dm644 /dev/null "$stamp_path"
}

borg_maybe_prune() {
	local repo=$1
	#local id=$(borg config "$repo" id)
	local id=$(awk '/^id = / {print $3}' "$repo/config")
	local stamp="borg_$id.prune"

	if check_stamp "$stamp" 30 0; then
		log "pruning old backups"
		borg prune "$repo" \
			"${borg_keep[@]}" \
			--verbose
		update_stamp "$stamp"
		borg list "$repo"
	fi
}

do_rsync() {
	local src=$1 dest=$2 rest=("${@:3}")

	local arg last args=()

	if [[ $src == / || $src == ~/ ]]; then
		debug "using 'sudo'"
		args+=(sudo)
	fi

	if have nocache; then
		debug "using 'nocache'"
		args+=(nocache)
	else
		notice "you should install 'nocache'"
	fi

	# note: add -x to jobs instead of here
	args+=(rsync "$src" "$dest"
		-aHAXvzh
		--info=progress2
		--delete-after
		--delete-excluded)

	for arg in "${rest[@]}"; do
		if [[ $last == -f && $arg == @(merge|.)\ * ]]; then
			debug "processing '$arg'"
			if [[ -f ${arg#* } ]]; then
				args+=("$arg")
			else
				debug "merge file not found, replacing with /dev/null"
				args+=("merge /dev/null")
			fi
		else
			args+=("$arg")
		fi
		last=$arg
	done

	log "rsyncing $src -> $dest"

	"${args[@]}"; r=$?

	(( !r )) ||	# success
	(( r == 24 ))	# files vanished
}

do_pull() {
	local dir=$1
	local url=$(cd "$dir" && git config remote.origin.url)

	log "updating repo $dir (from $url)"
	(cd "$dir" && git pull --ff-only origin)
}

do_annex_archive() {
	local remote
	local -i skipped=0 done=0 failed=0

	log "copying annex '$PWD' to archive"

	for remote in $(git remote); do
		if [[ $remote != vol* ]]; then
			debug "skipping mismatching remote '$remote'"
		elif ! git annex group $remote | grep -wqs archive; then
			warn "remote '$remote' ought to be in the 'archive' group"
			debug "skipping non-archive remote '$remote'"
			(( ++skipped ))
		elif ! git ls-remote $remote >&/dev/null; then
			debug "skipping unavailable remote '$remote'"
			(( ++skipped ))
		else
			do: git annex copy --in . --not --copies archive:1 --to $remote
			if (( $? == 0 )); then
				(( ++done ))
			else
				warn "archiving to remote '$remote' failed"
				(( ++failed ))
			fi
		fi
	done

	if (( done > 0 )); then
		return 0
	elif (( failed > 0 )); then
		err "failed archive data to any archive volume"
		return 1
	else
		err "no archive volumes available (skipped $skipped)"
		return 1
	fi
}

do_kinit() {
	log "obtaining Kerberos tickets"
	k5start_base=$(mktemp -d /tmp/backup_XXXXXXXX)
	export KRB5CCNAME="FILE:$k5start_base/krb5cc"
	k5start -K 15 -b -p "$k5start_base/pid" -L -q "$@"
	trap 'do_kdestroy' EXIT
}

do_kdestroy() {
	if [ -e "$k5start_base/pid" ]; then
		kill $(< "$k5start_base/pid")
		unset KRB5CCNAME
		rm -rf "$k5start_base"
	fi
}

do_job() {
	$0 "$1" || { failed_jobs+=("$1"); false; }
}

if [[ ! $_inhibited ]]; then
	export _inhibited=$$
	debug "restarting under gnome-inhibit"
	exec gnome-inhibit \
		--always \
		--who "backup" \
		--what "suspend" \
		--why "Performing a backup" \
		-- "$0" "$@"
fi

set -e
umask 077
debug "started with: '$*'"

trap "die \"[\$BASHPID] '\$job' interrupted\"" INT

while [[ $1 ]]; do
	job=${1%/}; shift

	take_lock "$job"
	log2 "running job '$job'"
	t_begin=$(now)

	case $job in
		push-hd)
			do_job local
			do_job home-push-hd
			do_job root-push-hd
			do_job annex-push-hd
			sync
			;;
		home-push-hd)
			do_rsync ~/ $bvol/Backup/Homes/$HOSTNAME/		\
				-f "merge $conf/rsync-filters/home_all"		\
				-f "merge $conf/rsync-filters/home_$HOSTNAME"	\
				-P
			;;
		root-push-hd)
			do_rsync / $bvol/Backup/Roots/$HOSTNAME/		\
				-f "exclude $HOME/"				\
				-f "merge $conf/rsync-filters/root_all"		\
				-f "merge $conf/rsync-filters/root_$HOSTNAME"	\
				-x -P
			;;
		annex-push-hd)
			failed=0
			for annex in "${annexes[@]}"; do
				(cd "$annex" && do_annex_archive) || (( ++failed ))
			done
			(( !failed ))
			;;
		borg@frost)
			repo="/vol4/Backup/Homes/$HOSTNAME.borg"
			tag="$HOSTNAME.$(date +%Y%m%d.%H%M%S)"
			borg_home_dirs=(.)
			borg_home_args=(
				"${borg_args[@]}"
				--exclude-from="$conf/borg/home_all.exclude"
				--exclude-from="$conf/borg/home_$HOSTNAME.exclude"
			)
			cd ~
			/bin/time \
			borg create "$repo::$tag" \
				"${borg_home_dirs[@]}" \
				"${borg_home_args[@]}" ;
			borg_maybe_prune "$repo"
			;;
		borg@dropbox)
			if [[ "$(dropbox exclude list)" != "No directories are being ignored." ]]; then
				die "cannot back up a partial Dropbox"
			fi
			repo="/vol4/Backup/Homes/Dropbox.borg"
			tag="$HOSTNAME.$(date +%Y%m%d.%H%M%S)"
			borg_dbox_dirs=(Dropbox/)
			borg_dbox_args=(
				"${borg_args[@]}"
				--exclude-from="$conf/borg/Dropbox.exclude"
				--files-cache="mtime,size"
			)
			cd ~
			borg create "$repo::$tag" \
				"${borg_dbox_dirs[@]}" \
				"${borg_dbox_args[@]}" ;
			borg_maybe_prune "$repo"
			;;
		pull)
			do_job twitter
			do_job servers
			do_job mail
			do_job irc
			if mountpoint -q $bvol; then
				do_job gale
			fi
			;;
		servers)
			homes=()
			roots=()
			etcs=()
			for host in "${hosts[@]}"; do
				if [[ $host == '#'* ]]; then
					continue
				elif [[ $host == *'!' ]]; then
					host=${host%!}
					roots+=($host)
				elif [[ $host == *'+' ]]; then
					host=${host%'+'}
					etcs+=($host)
				fi
				homes+=($host)
			done
			debug "backup home from: ${homes[*]}"
			debug "backup /etc from: ${etcs[*]}"
			debug "backup rootfs from: ${roots[*]}"
			debug "running jobs"
			for host in ${homes[@]}; do
				do_job @$host
			done
			for host in ${etcs[@]}; do
				do_job etc@$host
			done
			for host in ${roots[@]}; do
				do_job root@$host
			done
			if [[ $HOSTNAME == rain ]]; then
				do_job nanobot
				if mountpoint -q $bvol; then
					do_job fs1
				fi
			else
				notice "skipping nanobot and fs1 on $HOSTNAME"
			fi
			;;
		etc@*)
			host=${job#*@}
			do_rsync root@$host:/etc/ ~/Backup/Servers/$host.etc/		\
				-F -x -P --fake-super					;
			do_rsync root@$host:/ ~/Backup/Servers/$host.private/		\
				-f "merge $conf/rsync-filters/server_creds_all"		\
				-x -P --fake-super --prune-empty-dirs			;
			;;
		root@*)
			host=${job#*@}
			do_rsync root@$host:/ ~/Backup/Roots/$host/			\
				-f "merge $conf/rsync-filters/server_root_all"		\
				-f "merge $conf/rsync-filters/server_root_extra"	\
				-f "merge $conf/rsync-filters/server_root_$host"	\
				-F -x -P --fake-super					;
			;;
		@*)
			host=${job#@}
			do_rsync $host: ~/Backup/Homes/$host/				\
				-f "merge $conf/rsync-filters/home_all"			\
				-f "merge $conf/rsync-filters/home_$host"		\
				-f "merge $conf/rsync-filters/server_home_all"		\
				-f "merge $conf/rsync-filters/server_home_$host"	\
				-F -x -P						;
			;;
		fs1)
			do_rsync radius:pub/fs1/ $bvol/Backup/fs1/		\
				-f "exclude /mirrors/rain"			;
			;;
		mail)
			host=wolke
			do_rsync $host:Mail/      ~/Backup/Mail/$host/
			do_rsync $host:/srv/mail/ ~/Backup/Mail/$host-public/
			;;
		gphotos)
			do: rclone sync -v \
				"gdrive:Google Photos" \
				"$bvol/Backup/Google Drive Photos"
			;;
		nanobot)
			do_rsync root@panther:/home/nanobot/ ~/Backup/Cluenet/nanobot/
			;;
		twitter)
			twitter-backup
			;;
		irc)
			do_rsync virgule:irclogs/ ~/Attic/Chatlogs/current/
			;;
		cluenet)
			dir=~/Backup/Cluenet

			do_kinit -f "$dir/backup.keytab" -u "grawity/backup@CLUENET.ORG"
			do_pull $dir/virgule/accounts/
			#do_pull $dir/_ircd-config/
			do_kdestroy
			;;
		local)
			do_job local@$HOSTNAME
			;;
		local@rain)
			do_rsync \
				/win/Users/Mantas/AppData/Roaming/Firestorm_x64/ 	\
				~/Backup/Games/SL/Firestorm_current/			\
				-f "exclude browser_profile"				;
			do_job games@$HOSTNAME
			;;
		games@rain)
			(cd ~/Backup/Games && ./backup.sh)
			;;
		local@*)
			;;
		*)
			die "unknown job '$job'"
			;;
	esac || r=$?

	t_end=$(now)
	log "job '$job' finished in $(interval $[t_end-t_begin])"
	drop_lock

	if (( r )); then
		failed_jobs+=("$job")
		break
	fi
done

if (( ${#failed_jobs[@]} )); then
	_fail=${failed_jobs[*]}
	err "backup failed for ${_fail// /, }"
fi
