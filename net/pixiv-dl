#!/usr/bin/env python3
from nullroute.core import Core
from nullroute.misc import set_file_attr, set_file_attrs
from nullroute.api.pixiv import PixivApiClient
from nullroute.scrape import Scraper
import os
import re
import sys

def is_nonempty(file):
    if os.path.exists(file):
        if os.stat(file).st_size > 0:
            return True
    return False

class PixivGrabber():
    member_re = re.compile(r"https?://www\.pixiv\.net/member(?:_illust)?\.php\?id=(?P<id>\d+)")
    illust_re = re.compile(r"https?://www\.pixiv\.net/member_illust\.php\?mode=(?P<mode>manga|medium)&illust_id=(?P<id>\d+)")
    bigpage_re = re.compile(r"https?://www\.pixiv\.net/member_illust\.php\?mode=(?P<mode>manga_big)&illust_id=(?P<id>\d+)&page=(?P<page>\d+)")

    member_fmt = "https://www.pixiv.net/member_illust.php?id=%s"
    illust_fmt = "https://www.pixiv.net/member_illust.php?mode=medium&illust_id=%s"

    def __init__(self):
        self.api = PixivApiClient()
        self.s = Scraper()
        self.s.ua = self.api.ua
        self.write_log = True
        self.api._authenticate()

    def _check(self, r):
        if r.status != "success":
            Core.die("error %r" % r)
        return r

    def save_file(self, url, attrs=None):
        name = os.path.basename(url)
        if is_nonempty(name):
            Core.debug("file %r already exists, skipping" % name)
            return

        Core.debug("saving %s to %r" % (url, name))
        referer = url
        if attrs:
            referer = attrs.get("xdg.referrer.url", url)
        name = self.s.save_file(url, name,
                                referer=referer,
                                progress=True)
        if attrs:
            set_file_attrs(name, attrs)

    def _append_to_log(self, work):
        with open("pixiv%s.txt" % work.user.id, "a") as log:
            log.write("-- %s --\n" % work.id)
            log.write("Title: ｢%s｣\n" % work.title)
            log.write("Origin: <%s>\n" % (self.illust_fmt % work.id))
            log.write("\n")
            if work.caption:
                log.write("%s\n" % work.caption.replace("\r\n", "\n"))
                log.write("\n")

    def _save_work(self, work, only_pages=None):
        if (work.is_manga or work.type == "ugoira") and not work.metadata:
            Core.info("- refreshing metadata for work %s" % work.id)
            work = self.api.get_illust_info(work.id)

        attrs = {
            "dublincore.title": work.title,
            "dublincore.creator": "%s_pixiv%s" % (work.user.name, work.user.id),
            "xdg.referrer.url": self.illust_fmt % work.id,
        }

        if work.type == "ugoira":
            for size, url in work.metadata.zip_urls.items():
                Core.info("- saving zip %r" % size)
                self.save_file(url, attrs)
            with open("%s_delays.txt" % work.id, "w") as fh:
                delays = [frame.delay_msec for frame in work.metadata.frames]
                fh.write(str(delays))
        elif work.is_manga:
            Core.debug("- page whitelist %r" % only_pages)
            for j, page in enumerate(work.metadata.pages):
                # only_pages is 0-indexed, as are pages themselves,
                # but UI will show 1-indexed numbers
                if only_pages and j not in only_pages:
                    Core.debug("- skipping page %s, not in whitelist" % (j+1))
                    continue
                Core.info("- saving %r (page %s of %s)",
                          os.path.basename(page.image_urls["large"]),
                          j+1, work.page_count)
                self.save_file(page.image_urls["large"], attrs)
        else:
            self.save_file(work.image_urls["large"], attrs)

        if self.write_log:
            self._append_to_log(work)

    def save_one_work(self, illust_id, **kwargs):
        work = self.api.get_illust_info(illust_id)
        Core.info("downloading work: %s ｢%s｣" % (work.id, work.title))
        self._save_work(work, **kwargs)

    def save_all_member_works(self, member_id, start_page=1):
        Core.info("getting works of user %s" % member_id)
        while start_page:
            works_r = self._check(self.api.api.users_works(member_id, page=start_page))
            Core.info("got page %d/%d (%d works out of %d)" % (
                        works_r.pagination.current,
                        works_r.pagination.pages,
                        works_r.count,
                        works_r.pagination.total,
                      ))
            for i, work in enumerate(works_r.response):
                i_offset = (works_r.pagination.current - 1) * works_r.pagination.per_page
                i_global = (i + 1) + i_offset
                Core.info("downloading work %s of %s: %s ｢%s｣" % (
                            i_global,
                            works_r.pagination.total,
                            work.id,
                            work.title,
                          ))
                self._save_work(work)
            start_page = works_r.pagination.next

c = PixivGrabber()
c.write_log = False

args = sys.argv[1:]
if not args:
    Core.die("no URLs specified")

for arg in args:
    if arg == "--log":
        c.write_log = True
        continue

    m = c.bigpage_re.match(arg)
    if m:
        illust_id = int(m.group("id"))
        page_no = int(m.group("page"))
        c.save_one_work(illust_id, only_pages=[page_no])
        continue

    m = c.illust_re.match(arg)
    if m:
        mode = m.group("mode")
        if mode not in {"medium", "manga"}:
            Core.err("BUG: unrecognized mode %r in URL %r" % (mode, arg))
        illust_id = int(m.group("id"))
        c.save_one_work(illust_id)
        continue

    m = c.member_re.match(arg)
    if m:
        member_id = int(m.group("id"))
        c.save_all_member_works(member_id)
        continue

    try:
        member_id = int(arg)
    except ValueError:
        Core.err("unrecognized argument %r" % arg)
    else:
        c.save_all_member_works(member_id)
